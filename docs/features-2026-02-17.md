# Corvo Feature List

> Last verified: 2026-02-17. Cross-referenced against actual source code in `internal/store`, `internal/server`, and `internal/enterprise`.

---

## Core System

- **Enqueue / fetch / ack / fail** — full job lifecycle over HTTP/JSON
- **Priority queuing** — 3 tiers (high / normal / low), byte-sortable in Pebble so high-priority jobs are always fetched first
- **Scheduled / delayed jobs** — `scheduled_at` field; scheduler promotes them to pending on the leader
- **Cron / recurring jobs** — server-side cron evaluation, no worker involvement
- **Retries with configurable backoff** — linear or exponential, configurable base delay, max delay, max retries
- **Dead letter queue** — exhausted jobs move to `dead` state
- **Job TTL / expiration** — `expire_after`; scheduler reaps expired jobs
- **Unique / singleton jobs** — `unique_key` + `unique_period`; server returns duplicate status with existing job ID if key active
- **Job cancellation** — cancel pending or active jobs via API or CLI
- **Queue pause / resume / drain / clear / destroy**
- **Rate limiting per queue** — `rate_limit` + `rate_window_ms`
- **Concurrency limiting per queue** — `max_concurrency`
- **Job batches with callback** — enqueue N jobs as a group; server fires callback job when all complete
- **Job chains (sequential pipelines)** — `chain` definition on enqueue; server auto-advances steps; `on_failure` and `on_exit` handlers; `step_status: "exit"` to short-circuit
- **Job dependencies** — `depends_on` list; dependent job stays pending until all dependencies complete
- **Checkpointing** — workers save incremental state via heartbeat; survives crashes and lease reclaim
- **Job progress tracking** — `progress.current` / `progress.total` / `progress.message` reported via heartbeat
- **Held state + human-in-the-loop** — jobs pauseable pre-execution or mid-run; approve / reject / reject-and-revise via API/UI
- **Approval policies** — server-side rules that auto-hold jobs matching conditions (cost, iteration count, action type, queue pattern)
- **Bulk operations** — bulk retry, cancel, move, delete; piped from search output
- **Tags** — arbitrary key/value metadata on jobs, queryable and filterable
- **Job result storage** — ack payload stored as result; queryable
- **Webhooks** — fire-and-forget POST on job lifecycle events; configurable per-event filtering

---

## Reliability

- **Raft consensus** — all writes go through hashicorp/raft; quorum required for all state changes
- **Pebble as source of truth** — CockroachDB's pure-Go LSM-tree KV; no CGO on the write path
- **SQLite materialized view** — rebuildable from Pebble at any time; rich query surface for reads
- **At-least-once delivery** — lease + reclaim model; explicitly documented guarantee
- **Lease-based job locking** — fetch is a Raft op; lease default 60s; heartbeat extends
- **Automatic lease reclamation** — scheduler ticks every 1s; expired leases move jobs back to pending
- **Deterministic timestamps** — leader pre-computes `NowNs`; FSM never calls `time.Now()`; no clock-skew divergence between nodes
- **Crash recovery** — Raft log replay on startup; snapshot restore; `prepareFSMForRecovery()` prevents stale state
- **Snapshot-based log compaction** — Pebble checkpoint + SQLite backup; gzipped tar; 2 retained
- **Group-commit batching** — adaptive 100µs–8ms window; up to 1024 ops per Raft apply
- **SQLite rebuild** — `RebuildSQLiteFromPebble()` admin endpoint for diverged materialized view

---

## Worker Model

- **Language SDKs** — Go, TypeScript, Python, Rust; plain HTTP/JSON API works from any language
- **Long-poll fetch** — workers block waiting for jobs; no busy-polling
- **Bidirectional streaming** — `StreamLifecycle` Connect/gRPC bidi stream for fetch+ack on a single connection with lower overhead than pure HTTP polling
- **Multi-queue fetch** — single fetch request can claim from a prioritized list of queues
- **Heartbeat** — extends lease, reports progress and LLM usage; server signals `cancel` if job was reclaimed
- **Graceful shutdown** — worker gets SIGTERM, finishes active jobs, stops fetching
- **Backpressure signaling** — `OVERLOADED` response with `retry_after_ms` + jitter when server is saturated
- **Strike system** — progressive delay on consecutive errors; stream closed after 10 non-overload strikes

---

## Scaling

- **Single binary, zero external dependencies** — embedded Pebble + SQLite + Raft; no Postgres, Redis, or Zookeeper
- **Automatic clustering** — 3-node HA via Raft; leader election and failover built in; join via `POST /api/v1/cluster/join`
- **Follower write proxying** — followers proxy write requests to leader transparently; `StreamLifecycle` returns `NOT_LEADER` + leader addr for direct reconnect
- **Per-queue fetch semaphore** — `ApplyMaxFetchQueueInFly` (default 64) prevents one queue monopolizing the apply pipeline
- **Apply channel backpressure** — `ApplyMaxPending` (default 16384) buffered; returns 429 immediately when full
- **Kubernetes-native** — StatefulSet clustering, health check at `/healthz`, graceful SIGTERM shutdown
- **Configurable Raft log backend** — BoltDB, BadgerDB, or Pebble

---

## Observability

- **Web UI** — modern embedded SPA; real-time via SSE; job detail, queue stats, worker list, cost dashboard, held jobs view, cron schedules
- **CLI (`corvo`)** — enqueue, inspect, retry, cancel, move, delete, pause, resume, drain, clear, search, bulk ops, `corvo top` live TUI, `corvo cluster status`, `corvo workers`, `corvo schedules`; `--output json` on all commands for scripting
- **Prometheus metrics** — `/api/v1/metrics`; queue depths, throughput, worker counts
- **OpenTelemetry tracing** — `raft.apply` spans with `corvo.op_type` attribute; OTLP/HTTP or stdout exporter
- **Cluster status endpoint** — `apply_pending_now`, `queue_time_hist` (p50/p90/p99), `apply_time_hist`, `sqlite_mirror.lag`, `sqlite_mirror.dropped`, snapshot health
- **SSE event stream** — real-time job lifecycle events pushed to UI and API consumers
- **Per-job lifecycle event log** — optional (`LifecycleEvents` config flag); stored in Pebble
- **Job search** — filter by queue, state, tags, payload (jq supported), error message, date range
- **LLM usage tracking** — input/output tokens, model, provider, cost per job per attempt; reported on ack or heartbeat
- **Usage summary API** — `GET /api/v1/usage/summary?period=7d&group_by=queue|model|tag:*`
- **AI cost dashboard** — spend by queue and model in the UI
- **Audit log** — who did what, when (OSS included)

---

## API & SDK

- **REST/JSON API** — all endpoints curl-testable; no binary protocol required
- **Connect/gRPC** — bidirectional streaming lifecycle protocol for performance-sensitive workers
- **Webhook enqueue** — `POST /api/v1/webhooks/{queue}` for external job enqueuing
- **Key management API** — `POST/GET/DELETE /api/v1/auth/keys`
- **Bulk async API** — async bulk operations with job IDs for status polling
- **Full-text search endpoint** — payload search with jq filter support

---

## Security

- **API key auth** — `X-API-Key` or `Authorization: Bearer`; SHA-256 hashed at rest; raw value shown once on creation
- **4 built-in roles** — `admin`, `operator`, `readonly`, `worker` (worker role intentionally cannot pause queues or approve jobs)
- **Queue-scoped API keys** — glob patterns (`emails.*`); enforced on fetch, enqueue, search, and all job/queue operations
- **Key expiry** — `expires_at` enforced server-side
- **Development bootstrap mode** — auth disabled until first key is created; zero friction for local dev
- **Enterprise: OIDC bearer auth** — issuer discovery + JWKS verification (licensed)
- **Enterprise: SAML trusted-header mode** — proxy-terminated SAML (licensed)
- **Enterprise: Custom RBAC** — fine-grained resource + action permissions, multiple roles per key, additive union (licensed)
- **Enterprise: Multi-tenancy / namespace isolation** — keys scoped to namespace; cross-namespace only with `namespace: "*"` (licensed)
- **License system** — Ed25519-signed JWT; air-gap safe (no phone-home required); 7-day grace period on expiry

---

## AI / LLM-Specific

These features are built and tested in the current codebase. Some docs in `AI.md` describe features that were scoped or dropped — treat this section as the accurate list.

- **Agent loop primitive** — `agent` field on enqueue with `max_iterations`, `max_cost_usd`, `iteration_timeout`; server enforces guardrails; `agent_status: continue|done|hold` on ack
- **Iteration tracking** — `job_iterations` table; per-iteration checkpoint, model, cost, latency
- **Server-enforced agent guardrails** — max iterations, max cost; auto-holds job when exceeded
- **LLM usage reporting** — on ack and heartbeat; per-attempt and cumulative totals
- **Budget enforcement** — per-queue, per-tag, or global daily + per-job limits; `hold`, `reject`, or `alert_only` actions; enforced at fetch and ack
- **Approval policies** — auto-hold rules: `cost_usd_gt`, `agent_iteration_gt`, `hold_payload_action_in`, queue pattern matching
- **Replay from iteration** — `POST /api/v1/jobs/{id}/replay?from=N`; creates new job from checkpoint at iteration N
- **Result caching via unique jobs** — `unique_key` = hash of prompt + `unique_period` = cache TTL; no extra server machinery
- **Tool-as-child-job pattern** — `parent_id` links tool jobs to agent job; batch + callback for parallel tool execution with independent retries and rate limits
- **Human-in-the-loop** — held state with approve / reject / reject-and-revise-with-feedback flow; holds from budget exceed, approval policy, agent request, or explicit API call

---

## Differentiators vs Faktory / pgboss / BullMQ / Temporal

| Area | Corvo |
|---|---|
| Pricing | Every processing feature free in OSS. Faktory gates batches, progress, unique jobs, and throttling behind $149–949/mo. |
| Clustering | Automatic Raft HA — no external coordinator, no Postgres dependency. Faktory and BullMQ have no HA story. |
| Dependencies | Single binary, zero infra. `corvo server` and you're done. |
| AI/LLM | First-class: budgets, agent loop, cost tracking, human approval gates built into the server. Nothing else has this. |
| Worker protocol | Bidirectional streaming in addition to HTTP long-poll. Lower overhead for high-throughput workers. |
| Agent guardrails | Server-enforced iteration and cost limits. Workers don't implement their own loop control. |
| Job chains | Server-managed step advancement with `on_failure` / `on_exit` handlers — without a full workflow engine. |
| Dependency graph | `depends_on` for fan-in patterns without Temporal's DAG complexity. |
| Language support | Language-agnostic by design. Not Node-only (pgboss, BullMQ), not Go-only. Any language that speaks HTTP. |
| Observability | Full lifecycle trail in UI. Prometheus + OTEL built in. LLM cost dashboard. All free. |
